{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2ed335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openood.networks import ResNet18_32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace7c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir10 = './data/images_classic/cifar10/cifar10/train'\n",
    "test_dir10 = './data/images_classic/cifar10/cifar10/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ecba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations (augmentation and normalization)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807ea143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four classes and the remaining six classes\n",
    "classes_subset1 = ['airplane', 'automobile', 'ship', 'truck', 'cat', 'dog'] \n",
    "classes_subset2 =  ['frog', 'horse', 'bird', 'deer'] # Remaining classes\n",
    "\n",
    "# Load full CIFAR-10 dataset (assuming data_transforms is already defined)\n",
    "train_dir10 = './data/images_classic/cifar10/cifar10/train'\n",
    "test_dir10 = './data/images_classic/cifar10/cifar10/test'\n",
    "image_datasets10 = {\n",
    "    'train': datasets.ImageFolder(train_dir10, transform=data_transforms['train']),\n",
    "    'test': datasets.ImageFolder(test_dir10, transform=data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Function to filter dataset by classes\n",
    "def filter_by_classes(dataset, classes_to_include):\n",
    "    class_indices = [dataset.class_to_idx[cls] for cls in classes_to_include]\n",
    "    indices = [i for i, (_, label) in enumerate(dataset.samples) if label in class_indices]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Create subsets for the four classes and the other six classes\n",
    "subset1 = {'train':filter_by_classes(image_datasets10['train'], classes_subset1),\n",
    "              'test':filter_by_classes(image_datasets10['test'], classes_subset1)}\n",
    "subset2 = {'train':filter_by_classes(image_datasets10['train'], classes_subset2),\n",
    "            'test':filter_by_classes(image_datasets10['test'], classes_subset2)}\n",
    "\n",
    "# Create DataLoaders for each subset\n",
    "dataloaders_subset1 = {\n",
    "    'train': DataLoader(subset1['train'], batch_size=64, shuffle=True, num_workers=4),\n",
    "    'test': DataLoader(subset1['test'], batch_size=64, shuffle=False, num_workers=4)\n",
    "}\n",
    "dataloaders_subset2 = {\n",
    "    'train': DataLoader(subset2['train'], batch_size=64, shuffle=True, num_workers=4),\n",
    "    'test': DataLoader(subset2['test'], batch_size=64, shuffle=False, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae489a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARPL(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim=512):\n",
    "        super(ARPL, self).__init__()\n",
    "        self.feature_extractor = ResNet18_32x32(num_classes=10)\n",
    "        self.prototype_layer = nn.Parameter(torch.randn(num_classes, feature_dim))\n",
    "\n",
    "    def forward(self, x,rf=False):\n",
    "        x,features = self.feature_extractor(x,return_feature=True)\n",
    "        if rf:\n",
    "            return x, features\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "\n",
    "    def compute_loss(self, features, labels):\n",
    "        # Contrastive loss for prototype learning\n",
    "        prototypes = self.prototype_layer\n",
    "        distances = torch.cdist(features, prototypes)  # Pairwise distances\n",
    "        logits = -distances\n",
    "\n",
    "        ce_loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf7a5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            _,features = model(images,rf=True)\n",
    "            loss = model.compute_loss(features, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{20}], Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d6e43c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARPL(\n",
       "  (feature_extractor): ResNet18_32x32(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ARPL(num_classes=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f23b6af3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARPL(\n",
       "  (feature_extractor): ResNet18_32x32(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be5e2d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1453\n",
      "Epoch [2/20], Loss: 0.1333\n",
      "Epoch [3/20], Loss: 0.1293\n",
      "Epoch [4/20], Loss: 0.1191\n",
      "Epoch [5/20], Loss: 0.1106\n",
      "Epoch [6/20], Loss: 0.1085\n",
      "Epoch [7/20], Loss: 0.1006\n",
      "Epoch [8/20], Loss: 0.1012\n",
      "Epoch [9/20], Loss: 0.0897\n",
      "Epoch [10/20], Loss: 0.0875\n",
      "Epoch [11/20], Loss: 0.0821\n",
      "Epoch [12/20], Loss: 0.0768\n",
      "Epoch [13/20], Loss: 0.0731\n",
      "Epoch [14/20], Loss: 0.0678\n",
      "Epoch [15/20], Loss: 0.0669\n",
      "Epoch [16/20], Loss: 0.0627\n",
      "Epoch [17/20], Loss: 0.0617\n",
      "Epoch [18/20], Loss: 0.0571\n",
      "Epoch [19/20], Loss: 0.0551\n",
      "Epoch [20/20], Loss: 0.0516\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloaders_subset1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "436d8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def get_curve_online(known, novel, stypes=['Bas']):\n",
    "    tp, fp = dict(), dict()\n",
    "    tnr_at_tpr95 = dict()\n",
    "    for stype in stypes:\n",
    "        known.sort()\n",
    "        novel.sort()\n",
    "        end = np.max([np.max(known), np.max(novel)])\n",
    "        start = np.min([np.min(known), np.min(novel)])\n",
    "        num_k = known.shape[0]\n",
    "        num_n = novel.shape[0]\n",
    "        tp[stype] = -np.ones([num_k+num_n+1], dtype=int)\n",
    "        fp[stype] = -np.ones([num_k+num_n+1], dtype=int)\n",
    "        tp[stype][0], fp[stype][0] = num_k, num_n\n",
    "        k, n = 0, 0\n",
    "        for l in range(num_k+num_n):\n",
    "            if k == num_k:\n",
    "                tp[stype][l+1:] = tp[stype][l]\n",
    "                fp[stype][l+1:] = np.arange(fp[stype][l]-1, -1, -1)\n",
    "                break\n",
    "            elif n == num_n:\n",
    "                tp[stype][l+1:] = np.arange(tp[stype][l]-1, -1, -1)\n",
    "                fp[stype][l+1:] = fp[stype][l]\n",
    "                break\n",
    "            else:\n",
    "                if novel[n] < known[k]:\n",
    "                    n += 1\n",
    "                    tp[stype][l+1] = tp[stype][l]\n",
    "                    fp[stype][l+1] = fp[stype][l] - 1\n",
    "                else:\n",
    "                    k += 1\n",
    "                    tp[stype][l+1] = tp[stype][l] - 1\n",
    "                    fp[stype][l+1] = fp[stype][l]\n",
    "        tpr95_pos = np.abs(tp[stype] / num_k - .95).argmin()\n",
    "        tnr_at_tpr95[stype] = 1. - fp[stype][tpr95_pos] / num_n\n",
    "    return tp, fp, tnr_at_tpr95\n",
    "\n",
    "def metric_ood(x1, x2, stypes=['Bas'], verbose=True):\n",
    "    tp, fp, tnr_at_tpr95 = get_curve_online(x1, x2, stypes)\n",
    "    results = dict()\n",
    "    mtypes = ['TNR', 'AUROC', 'DTACC', 'AUIN', 'AUOUT']\n",
    "    if verbose:\n",
    "        print('      ', end='')\n",
    "        for mtype in mtypes:\n",
    "            print(' {mtype:6s}'.format(mtype=mtype), end='')\n",
    "        print('')\n",
    "        \n",
    "    for stype in stypes:\n",
    "        if verbose:\n",
    "            print('{stype:5s} '.format(stype=stype), end='')\n",
    "        results[stype] = dict()\n",
    "        \n",
    "        # TNR\n",
    "        mtype = 'TNR'\n",
    "        results[stype][mtype] = 100.*tnr_at_tpr95[stype]\n",
    "        if verbose:\n",
    "            print(' {val:6.3f}'.format(val=results[stype][mtype]), end='')\n",
    "        \n",
    "        # AUROC\n",
    "        mtype = 'AUROC'\n",
    "        tpr = np.concatenate([[1.], tp[stype]/tp[stype][0], [0.]])\n",
    "        fpr = np.concatenate([[1.], fp[stype]/fp[stype][0], [0.]])\n",
    "        results[stype][mtype] = 100.*(-np.trapz(1.-fpr, tpr))\n",
    "        if verbose:\n",
    "            print(' {val:6.3f}'.format(val=results[stype][mtype]), end='')\n",
    "        \n",
    "        # DTACC\n",
    "        mtype = 'DTACC'\n",
    "        results[stype][mtype] = 100.*(.5 * (tp[stype]/tp[stype][0] + 1.-fp[stype]/fp[stype][0]).max())\n",
    "        if verbose:\n",
    "            print(' {val:6.3f}'.format(val=results[stype][mtype]), end='')\n",
    "        \n",
    "        # AUIN\n",
    "        mtype = 'AUIN'\n",
    "        denom = tp[stype]+fp[stype]\n",
    "        denom[denom == 0.] = -1.\n",
    "        pin_ind = np.concatenate([[True], denom > 0., [True]])\n",
    "        pin = np.concatenate([[.5], tp[stype]/denom, [0.]])\n",
    "        results[stype][mtype] = 100.*(-np.trapz(pin[pin_ind], tpr[pin_ind]))\n",
    "        if verbose:\n",
    "            print(' {val:6.3f}'.format(val=results[stype][mtype]), end='')\n",
    "        \n",
    "        # AUOUT\n",
    "        mtype = 'AUOUT'\n",
    "        denom = tp[stype][0]-tp[stype]+fp[stype][0]-fp[stype]\n",
    "        denom[denom == 0.] = -1.\n",
    "        pout_ind = np.concatenate([[True], denom > 0., [True]])\n",
    "        pout = np.concatenate([[0.], (fp[stype][0]-fp[stype])/denom, [.5]])\n",
    "        results[stype][mtype] = 100.*(np.trapz(pout[pout_ind], 1.-fpr[pout_ind]))\n",
    "        if verbose:\n",
    "            print(' {val:6.3f}'.format(val=results[stype][mtype]), end='')\n",
    "            print('')\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compute_oscr(pred_k, pred_u, labels):\n",
    "    x1, x2 = np.max(pred_k, axis=1), np.max(pred_u, axis=1)\n",
    "    pred = np.argmax(pred_k, axis=1)\n",
    "    correct = (pred == labels)\n",
    "    m_x1 = np.zeros(len(x1))\n",
    "    m_x1[pred == labels] = 1\n",
    "    k_target = np.concatenate((m_x1, np.zeros(len(x2))), axis=0)\n",
    "    u_target = np.concatenate((np.zeros(len(x1)), np.ones(len(x2))), axis=0)\n",
    "    predict = np.concatenate((x1, x2), axis=0)\n",
    "    n = len(predict)\n",
    "\n",
    "    # Cutoffs are of prediction values\n",
    "    \n",
    "    CCR = [0 for x in range(n+2)]\n",
    "    FPR = [0 for x in range(n+2)] \n",
    "\n",
    "    idx = predict.argsort()\n",
    "\n",
    "    s_k_target = k_target[idx]\n",
    "    s_u_target = u_target[idx]\n",
    "\n",
    "    for k in range(n-1):\n",
    "        CC = s_k_target[k+1:].sum()\n",
    "        FP = s_u_target[k:].sum()\n",
    "\n",
    "        # True Positive Rate\n",
    "        CCR[k] = float(CC) / float(len(x1))\n",
    "        # False Positive Rate\n",
    "        FPR[k] = float(FP) / float(len(x2))\n",
    "\n",
    "    CCR[n] = 0.0\n",
    "    FPR[n] = 0.0\n",
    "    CCR[n+1] = 1.0\n",
    "    FPR[n+1] = 1.0\n",
    "\n",
    "    # Positions of ROC curve (FPR, TPR)\n",
    "    ROC = sorted(zip(FPR, CCR), reverse=True)\n",
    "\n",
    "    OSCR = 0\n",
    "\n",
    "    # Compute AUROC Using Trapezoidal Rule\n",
    "    for j in range(n+1):\n",
    "        h = ROC[j][0] - ROC[j+1][0]\n",
    "        w = (ROC[j][1] + ROC[j+1][1]) / 2.0\n",
    "\n",
    "        OSCR = OSCR + h*w\n",
    "\n",
    "    return OSCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8fb54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARPLoss(nn.Module):\n",
    "    def __init__(self, feat_dim=512, num_classes=10, **kwargs):\n",
    "        super(ARPLoss, self).__init__()\n",
    "        self.prototype_layer = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        prototypes = self.prototype_layer.to(features.device)  \n",
    "        distances = torch.cdist(features, prototypes)  # Pairwise distances\n",
    "        logits = -distances\n",
    "\n",
    "        if labels is None:\n",
    "            return logits, 0\n",
    "\n",
    "        ce_loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return logits, ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6136bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ARPLoss()\n",
    "\n",
    "# Define options\n",
    "options = {'use_gpu': True}\n",
    "\n",
    "def test(net, criterion, testloader, outloader, epoch=None, **options):\n",
    "    net.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    _pred_k, _pred_u, _labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in testloader:\n",
    "            if options['use_gpu']:\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                y, x = net(data, True)\n",
    "                logits, _ = criterion(x, y)\n",
    "                predictions = logits.data.max(1)[1]\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions == labels.data).sum()\n",
    "\n",
    "                _pred_k.append(logits.data.cpu().numpy())\n",
    "                _labels.append(labels.data.cpu().numpy())\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(outloader):\n",
    "            if options['use_gpu']:\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                y, x = net(data, True)\n",
    "                logits, _ = criterion(x, y)\n",
    "                _pred_u.append(logits.data.cpu().numpy())\n",
    "\n",
    "    # Accuracy\n",
    "    acc = float(correct) * 100. / float(total)\n",
    "    print('Acc: {:.5f}'.format(acc))\n",
    "\n",
    "    _pred_k = np.concatenate(_pred_k, 0)\n",
    "    _pred_u = np.concatenate(_pred_u, 0)\n",
    "    _labels = np.concatenate(_labels, 0)\n",
    "\n",
    "    # Out-of-Distribution detection evaluation\n",
    "    x1, x2 = np.max(_pred_k, axis=1), np.max(_pred_u, axis=1)\n",
    "    results = metric_ood(x1, x2)['Bas']\n",
    "\n",
    "    # OSCR\n",
    "    _oscr_score = compute_oscr(_pred_k, _pred_u, _labels)\n",
    "\n",
    "    results['ACC'] = acc\n",
    "    results['OSCR'] = _oscr_score * 100.\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5a48e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.70000\n",
      "       TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "Bas     0.025 20.417 50.000 43.519 26.247\n"
     ]
    }
   ],
   "source": [
    "results = test(model, criterion, dataloaders_subset1['test'], dataloaders_subset2['test'], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36061138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class airplane: 0.10%\n",
      "Accuracy for class automobile: 0.00%\n",
      "Accuracy for class bird: No samples\n",
      "Accuracy for class cat: 0.10%\n",
      "Accuracy for class deer: No samples\n",
      "Accuracy for class dog: 0.10%\n",
      "Accuracy for class frog: No samples\n",
      "Accuracy for class horse: No samples\n",
      "Accuracy for class ship: 0.00%\n",
      "Accuracy for class truck: 0.00%\n"
     ]
    }
   ],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track accuracy per class\n",
    "correct_preds = {classname: 0 for classname in class_names}\n",
    "total_preds = {classname: 0 for classname in class_names}\n",
    "\n",
    "# Evaluation loop\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders_subset1['test']:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        outputs= model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Track accuracy for each class\n",
    "        for label, pred in zip(labels, preds):\n",
    "            if pred == label:\n",
    "                correct_preds[class_names[label]] += 1\n",
    "            total_preds[class_names[label]] += 1\n",
    "\n",
    "for classname, correct_count in correct_preds.items():\n",
    "    if total_preds[classname] > 0:\n",
    "        accuracy = 100 * float(correct_count) / total_preds[classname]\n",
    "        print(f'Accuracy for class {classname}: {accuracy:.2f}%')\n",
    "    else:\n",
    "        print(f'Accuracy for class {classname}: No samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b66931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09941666666666202"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['OSCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d198de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Openood",
   "language": "python",
   "name": "openood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
